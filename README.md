# 2º Desafio Big Data | Indra + Uniesp
### Desafio Big Data promovido pela Indra e Uniesp. Desafio voltado ao Bash, Shell Script, HDFS, Hive e particionamento.

Neste desafio você vai executar a 1ª ingestão já esta configurada.

* **Etapa 1** - Executar rollout.sh
* **Etapa 2** - Executar o malha/jobs.sh (primeira ingestão), contudo que se pede
* **Etapa 3** - Desenhar um mapa mental da solução em qualquer ferramenta eu uso muito o (Draw.io), detalhando as etapas passando por cada script, detalhando o máximo o entendimento de vocês.
* **Etapa 4** - Configurar e executar a ingestão da pasta dados/second_ingestion
* **Etapa 5** - Ingerir dados em uma novas tabelas externas e internas do Hive referente ao arquivo cursos.csv (novo rollout e scripts) 
* **Etapa 6** - Ingerir dados em uma novas tabelas externas e internas do Hive referente ao arquivo unidades.csv (novo rollout e scripts) 
* **Etapa 7** - Executar o rollback.sh

