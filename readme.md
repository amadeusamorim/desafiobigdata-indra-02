# DESAFIO 2 SEMANA BIG DATA HIVE

É muito importante entender o fluxo de desenvolvimento de um pipe line de dados, neste desafio você executara a 1 ingestão que já esta configurada.

- etapa 1 - executar rollout.sh
- etapa 2 - executar o malha/jobs.sh (primeira ingestão), contudo que se pede
- etapa 3 - desenhar um mapa mental da solução em qualquer ferramenta eu uso muito o (Draw.io), detalhando as etapas passando por cada script, detalhando o maxino o entendimento de vocês.
- etapa 4 - configurar e executar a ingestão da pasta dados/second_ingestion
- etapa 5 - executa o rollback.sh


### IMPORTANTE

este desafio não é obrigatório, tem apenas como finalidade passar um cenário de um projeto possível, para que vocês tenham uma noção como é o dia a dia de um Engenheiro de Dados. 
**desta vez a maneira já esta criada, procure entender o maximo que for possivel**.

* Pesquize
* Neste projeto foi usando muitas variavel globais em linux, nome de pasta passando por parametro...
* Converse com seus Amigos
* Compartilhe seus resultados em suas redes
* Se divirta
* Aprenda bastante
* Usem o github
       
## Etapas e Explicações

SERVIDOR: hive-server

1 - Efetuar o Download do pacote usando o CURL ou usar o Github para clonar o projeto

curl -O https://github.com/caiuafranca/desafio_bigdata_hive/archive/refs/heads/master.zip

ou git clone https://github.com/caiuafranca/desafio_bigdata_hive.git

### OBS 

usem e abusem do echo para evidenciar o seu processo em tela

echo "Aproveitem a Jornada para adquirir conhecimento"
